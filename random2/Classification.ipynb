{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataframe = pd.DataFrame.from_csv('base_train.csv',sep=';',index_col=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that all variables are binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0, 42602, 42602, 42602, 42602, 42602, 42602, 42602,\n",
       "       42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602,\n",
       "       42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602,\n",
       "       42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602,\n",
       "       42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602, 42602,\n",
       "       42602, 42602, 42602, 42602, 42602, 42602, 42602, 31083, 31083])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that sum of 1 and 0 values equals to the dimension of the data\n",
    "dataset = dataframe.values\n",
    "sum((dataset == 0)*1)+sum((dataset == 1)*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First two columns include date and ID correspondingly. To incorporate date into analysis we replace it by the month number. Thus we'll have a new variable with 12 values which reflects dependency of the output from the month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert dates to datetime format\n",
    "dataframe['report_dt'] = pd.to_datetime(dataframe['report_dt'])\n",
    "# extract month numbers\n",
    "month = numpy.zeros(len(dataframe))\n",
    "for i in range(len(dataframe)):\n",
    "    month[i] = dataframe['report_dt'][i].month\n",
    "#replace date with month number\n",
    "dataframe['report_dt'] = month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "report_dt        0\n",
       "ID               0\n",
       "1.1.             0\n",
       "1.2.             0\n",
       "1.3.             0\n",
       "1.4.             0\n",
       "1.5.             0\n",
       "1.6.             0\n",
       "1.7.             0\n",
       "1.8.             0\n",
       "1.9.             0\n",
       "1.10.            0\n",
       "1.11.            0\n",
       "1.12.            0\n",
       "1.13.            0\n",
       "1.14.            0\n",
       "1.15.            0\n",
       "1.16.            0\n",
       "1.17.            0\n",
       "1.18.            0\n",
       "1.19.            0\n",
       "2.1.             0\n",
       "2.2.             0\n",
       "2.3.             0\n",
       "2.4.             0\n",
       "2.5.             0\n",
       "2.6.             0\n",
       "2.7.             0\n",
       "2.8.             0\n",
       "2.9.             0\n",
       "2.10.            0\n",
       "2.11.            0\n",
       "2.12.            0\n",
       "2.13.            0\n",
       "2.14.            0\n",
       "2.15.            0\n",
       "2.16.            0\n",
       "3.1.             0\n",
       "3.2.             0\n",
       "3.3.             0\n",
       "3.4.             0\n",
       "3.5.             0\n",
       "3.6.             0\n",
       "3.7.             0\n",
       "3.8.             0\n",
       "3.9.             0\n",
       "3.10.            0\n",
       "3.11.            0\n",
       "3.12.            0\n",
       "3.13.            0\n",
       "3.14.            0\n",
       "3.15.            0\n",
       "X3           11519\n",
       "Y3           11519\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of missing inputs and outputs\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing inputs, but about 25% of outputs are missing. We need to exclude those records from the dataset, as they aren't valid both for trainig and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete data with missing values\n",
    "dataframe = dataframe.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we test how the dataset is balanced, i.e. what is the proportion of 0 and 1 values of output variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of 1 values in X3 variable\n",
    "sum((dataframe['X3'] ==1)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of 1 values in Y3 variable\n",
    "sum((dataframe['Y3'] ==1)*1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that value 1 is obtained by less then 1/30 of the dataset. Which means that we'll need to apply different weights to 0 and 1 during trainig to balance classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there's no a priori information about dependencies in the date we delete column ID. Also as we don't know the nature of the output variables (if ther's any connection between them) we use separate models to predict X3 and Y3. Next we predict X3 variable (to predict Y3 change \"del dataframe['Y3']\" to \"del dataframe['X3']\" in the code box below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del dataframe['report_dt']\n",
    "del dataframe['ID']\n",
    "del dataframe['Y3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select features that have the highest scores using chi2 function for scoring. However we should note that this is not required if we use a neural network (usually it's assumed that this step is performed by the network itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate scores of featuress\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "values = SelectKBest(chi2, k='all').fit(dataframe.drop('X3',axis=1).values,dataframe['X3'].values)\n",
    "scores = -numpy.log10(values.pvalues_)\n",
    "\n",
    "# uncomment code below to plot results\n",
    "#%matplotlib inline\n",
    "#plt.bar(range(len(dataframe.columns)-1), scores)\n",
    "#plt.xticks(range(len(dataframe.columns)-1), dataframe.columns, rotation='vertical')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we leave 30 features with highest scores and drop others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select K best features and transform dataset\n",
    "dataset_reduced = SelectKBest(chi2, k=30).fit_transform(dataframe.drop('X3',axis=1).values,dataframe['X3'].values)\n",
    "dataset_reduced = numpy.append(dataset_reduced,numpy.reshape(dataframe['X3'].values,(len(dataframe['X3'].values),1)),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last step we split data into training and test sets in proportion 3/1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into trainig (75%) and test (25%) sets\n",
    "train, test = sk.cross_validation.train_test_split(dataset_reduced, test_size = 0.25)\n",
    "# split into input (X) and (Y) variables\n",
    "Xtrain = train[:,0:train.shape[1]-1]\n",
    "Ytrain = train[:,train.shape[1]-1]\n",
    "Xtest = test[:,0:test.shape[1]-1]\n",
    "Ytest = test[:,test.shape[1]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a fully-connected network with three layers. The network weights are initialized to a small random number drawn from a uniform distribution. As an activation function on the first two layers we use the rectifier function 'relu'. In the last layer we use sigmoid to insure the output is between 0 and 1. First layer has 35 neurons, 2nd layer 24 neurons, the output layer has 1 neuron to predict the output. Between hiden layers we also perform dropout operation for better distribution of weights between neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(35, input_dim=train.shape[1]-1, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(24, init='uniform', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best set of weights we must specify: the loss function, optimizer and metrics that we want to calculate during training. For binary classification problem we pick \"binary_crossentropy\" loss. The optimization method is gradient descent \"adadelta\". We calculate classification accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model. We pick 300 iterations for the optimization algorithm and a batch size of 32. Each epoch separates 20% of data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10ecc54d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(Xtrain,Ytrain, validation_split=0.2, nb_epoch=300, batch_size=32, class_weight=\"balanced\", verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after the model is ready, we generate predicitons on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7040/7771 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "# make prediction on test set\n",
    "Ypred= model.predict_classes(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we build the decision tree model using sklearn framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create and fit model\n",
    "modeltree = tree.DecisionTreeClassifier()\n",
    "modeltree.fit(Xtrain, Ytrain)\n",
    "\n",
    "# make prediction on test set\n",
    "Ypredtree = modeltree.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a batch of trees, we'll check it's perpormance too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the random forest\n",
    "modelforest = RandomForestClassifier(n_estimators = 100)\n",
    "modelforest.fit(Xtrain,Ytrain)\n",
    "\n",
    "# make prediction on test set\n",
    "Ypredforest = modelforest.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model is the SVM classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create and fit model\n",
    "modelsvm = svm.SVC()\n",
    "modelsvm.fit(Xtrain, Ytrain)\n",
    "\n",
    "# make prediction on test set\n",
    "Ypredsvm = modelsvm.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelreg = sk.linear_model.LogisticRegression()\n",
    "modelreg.fit(Xtrain,Ytrain)\n",
    "\n",
    "Ypredreg = modelreg.predict(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define a function that evaluates performance of the model through different metrics. Short description for each metric is given in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluation(Xtest,Ytest,Ypred):\n",
    "    \n",
    "    # accuracy on test set\n",
    "    score = sk.metrics.accuracy_score(Ytest,Ypred)\n",
    "    print 'accuracy:', round(score*100,2), '%'\n",
    "    \n",
    "    # precision on test set\n",
    "    # The precision is the ratio tp / (tp + fp) where tp is the\n",
    "    # number of true positives and fp the number of false positives.\n",
    "    # The best value is 1 and the worst value is 0.\n",
    "    score = sk.metrics.precision_score(Ytest,Ypred)\n",
    "    print 'precision:', round(score*100,2), '%' \n",
    "    \n",
    "    # recall on test set\n",
    "    # The recall is the ratio tp / (tp + fn) where tp is the number of\n",
    "    # true positives and fn the number of false negatives.\n",
    "    # The best value is 1 and the worst value is 0.\n",
    "    score = sk.metrics.recall_score(Ytest,Ypred)\n",
    "    print 'recall:', round(score*100,2), '%'\n",
    "    \n",
    "    # f1 score on test set\n",
    "    # The F1 score can be interpreted as a weighted average of the \n",
    "    # precision and recall, where an F1 score reaches its best value at\n",
    "    # 1 and worst score at 0.\n",
    "    score = sk.metrics.f1_score(Ytest,Ypred)\n",
    "    print 'f1:', score\n",
    "    \n",
    "    # Area Under the Curve from prediction scores\n",
    "    # The best performance is 1\n",
    "    score = sk.metrics.roc_auc_score(Ytest,Ypred)\n",
    "    print 'AUC:', score  \n",
    "    \n",
    "    # Confusion matrix\n",
    "    # By definition a confusion matrix C is such that C_{i, j} \n",
    "    # is equal to the number of observations known to be in group i \n",
    "    # but predicted to be in group j.\n",
    "    print 'Confusion matrix:'\n",
    "    print sk.metrics.confusion_matrix(Ytest,Ypred)\n",
    "    \n",
    "    # Matthews correlation coefficient (phi coefficient)\n",
    "    # Is used in machine learning \n",
    "    # as a measure of the quality of binary (two-class) classifications.\n",
    "    # It takes into account true and false positives and negatives and \n",
    "    # is generally regarded as a balanced measure which can be used even\n",
    "    # if the classes are of very different sizes. \n",
    "    #+1 perfect prediction; 0 random prediction; -1 inverse prediction\n",
    "    score = sk.metrics.matthews_corrcoef(Ytest,Ypred)\n",
    "    print 'MCC:', score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets evaluate each model performance. First goes the neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.53 %\n",
      "precision: 82.78 %\n",
      "recall: 64.22 %\n",
      "f1: 0.723300970874\n",
      "AUC: 0.819064714062\n",
      "Confusion matrix:\n",
      "[[7508   31]\n",
      " [  83  149]]\n",
      "MCC: 0.721977875198\n"
     ]
    }
   ],
   "source": [
    "evaluation(Xtest,Ytest,Ypred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.52 %\n",
      "precision: 80.95 %\n",
      "recall: 65.95 %\n",
      "f1: 0.726840855107\n",
      "AUC: 0.82735379475\n",
      "Confusion matrix:\n",
      "[[7503   36]\n",
      " [  79  153]]\n",
      "MCC: 0.723311628753\n"
     ]
    }
   ],
   "source": [
    "evaluation(Xtest,Ytest,Ypredtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.57 %\n",
      "precision: 82.01 %\n",
      "recall: 66.81 %\n",
      "f1: 0.736342042755\n",
      "AUC: 0.831796783164\n",
      "Confusion matrix:\n",
      "[[7505   34]\n",
      " [  77  155]]\n",
      "MCC: 0.73312872951\n"
     ]
    }
   ],
   "source": [
    "evaluation(Xtest,Ytest,Ypredforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 98.12 %\n",
      "precision: 72.4 %\n",
      "recall: 59.91 %\n",
      "f1: 0.655660377358\n",
      "AUC: 0.79605391047\n",
      "Confusion matrix:\n",
      "[[7486   53]\n",
      " [  93  139]]\n",
      "MCC: 0.649150048349\n"
     ]
    }
   ],
   "source": [
    "evaluation(Xtest,Ytest,Ypredsvm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the log regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 97.93 %\n",
      "precision: 73.51 %\n",
      "recall: 47.84 %\n",
      "f1: 0.579634464752\n",
      "AUC: 0.736571266197\n",
      "Confusion matrix:\n",
      "[[7499   40]\n",
      " [ 121  111]]\n",
      "MCC: 0.583346900674\n"
     ]
    }
   ],
   "source": [
    "evaluation(Xtest,Ytest,Ypredreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should not be confused with a value of accuracy which is so high just due to the unbalanced dataset. Precision, recall and f1 score (as well as other metrics) show similar performance for all the models (a bit lower for log regression). The MCC value shows that our predictions are not random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remark: though variables X3 and Y3 are correlated (with coefficient approx 0.82) we do not to combine them into a single model as usually some additional knowledge of variables domain is needed to do so. Without explicit knowledge of the dependencies it is prefered to treat outputs separately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
